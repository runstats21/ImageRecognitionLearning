{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tensor flow functions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, InputLayer, Dropout,GaussianNoise,RandomContrast\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to image folders\n",
    "img_folders_path = '256_ObjectCategories/sim_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.ops.numpy_ops import np_config\n",
    "# np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4232 images belonging to 46 classes.\n",
      "Found 1038 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "datagen = ImageDataGenerator(rescale=1./255, # converts pixels in range 0,255 to between 0 and 1\n",
    "                             # this will make every image contribute more evenly to the total loss\n",
    "                            validation_split=0.2)\n",
    "\n",
    "# if want to implement gray scale:\n",
    "def to_grayscale(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    return image\n",
    "\n",
    "# then use preprocessing_function=to_grayscale in ImageDataGenerator\n",
    "traingen_g = ImageDataGenerator(rescale=1./255,\n",
    "                                validation_split = 0.2,\n",
    "                                preprocessing_function=to_grayscale)\n",
    "\n",
    "# if split into train and test dirs, could apply brightness range to\n",
    "# only test set using \"brightness_range\" option in ImageDataGenerator\n",
    "traingen_b = ImageDataGenerator(rescale=1./255,\n",
    "                                validation_split = 0.2,\n",
    "                                brightness_range = [0.5,1.5])\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    img_folders_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# in case I want to experiment with brightness as an augmentation\n",
    "# train_generator_b = traingen_b.flow_from_directory(\n",
    "#     img_folders_path,\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=32,\n",
    "#     shuffle = True,\n",
    "#     class_mode='categorical',\n",
    "#     subset='training'\n",
    "# )\n",
    "\n",
    "# or with gray scale as augmentation\n",
    "# train_generator_g = traingen_g.flow_from_directory(\n",
    "#     img_folders_path,\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=32,\n",
    "#     shuffle = True,\n",
    "#     class_mode='categorical',\n",
    "#     subset='training'\n",
    "# )\n",
    "\n",
    "\n",
    "# will use this validation set as a test set, as val metrics can be used for early stopping and ability for tuning,\n",
    "# but do not affect training (according to search I made)\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    img_folders_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define important parameters\n",
    "num_classes = len(np.unique(train_generator.classes))\n",
    "noise_sd = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create early stopping\n",
    "es = EarlyStopping(monitor='loss',patience=3,mode='min')\n",
    "# could also add \"start_from_epoch\" specification in this es object\n",
    "# in .fit() add the following to implement early stopping:\n",
    "# callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      " 20/133 [===>..........................] - ETA: 1:24 - loss: 4.9638 - accuracy: 0.0219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tyler\\Dropbox\\BYU\\STAT 666\\Term Project\\work.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# there may also be some overfitting, so using some dropout could be helpful\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model_ffn_nc\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                   metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model_ffn_nc\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             \u001b[39m#   steps_per_epoch=10,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[es])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m model_ffn_nc\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ffn = Sequential([\n",
    "    RandomContrast(0, input_shape=(150, 150, 3)),\n",
    "    GaussianNoise(0),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    # 5 classes: so get 5 output nuerons with softmax activiation function (to give probability of each class)\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# there may also be some overfitting, so using some dropout could be helpful\n",
    "\n",
    "model_ffn.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_ffn.fit(train_generator, epochs=10,\n",
    "            #   steps_per_epoch=10,\n",
    "                callbacks=[es])\n",
    "model_ffn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [5.510605812072754, 4.4738874435424805],\n",
       " 'accuracy': [0.01875000074505806, 0.03750000149011612]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_ffn.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  4/133 [..............................] - ETA: 1:09 - loss: 3.8790 - accuracy: 0.0312  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tyler\\Dropbox\\BYU\\STAT 666\\Term Project\\work.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_cnn \u001b[39m=\u001b[39m Sequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# syntax: Conv2D(num_filters, kernel_size (shape1,shape2), activation, input_shape for first layer)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# RandomContrast(0.2, input_shape=(150, 150, 3)),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     Dense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model_cnn\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                   metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model_cnn\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m               callbacks \u001b[39m=\u001b[39;49m [es])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# default is to take len(train_generator steps per epoch)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model_cnn\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential([\n",
    "    # syntax: Conv2D(num_filters, kernel_size (shape1,shape2), activation, input_shape for first layer)\n",
    "    # RandomContrast(0.2, input_shape=(150, 150, 3)),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    # after convolutional layers, flatten the output, then use 1-2(/3?) dense layers\n",
    "    Flatten(),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    Dense(256, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    # GaussianNoise(noise_sd),\n",
    "    # Dense(128, activation='relu'),\n",
    "    # Dropout(0.1),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_cnn.fit(train_generator, epochs=10,\n",
    "              callbacks = [es])\n",
    "# default is to take len(train_generator steps per epoch)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ffn_model\\assets\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "INFO:tensorflow:Assets written to: ffn_model_nc\\assets\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tyler\\Dropbox\\BYU\\STAT 666\\Term Project\\work.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_ffn\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mffn_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_ffn_nc\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mffn_model_nc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_ffn_c\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39mffn_model_c\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_ffn_n\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mffn_model_n\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_cnn\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mcnn_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2435\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2393\u001b[0m \u001b[39m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   2394\u001b[0m \n\u001b[0;32m   2395\u001b[0m \u001b[39mPlease see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2432\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2434\u001b[0m \u001b[39m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m-> 2435\u001b[0m save\u001b[39m.\u001b[39;49msave_model(\u001b[39mself\u001b[39;49m, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m   2436\u001b[0m                 signatures, options, save_traces)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\saving\\save.py:153\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m   \u001b[39mwith\u001b[39;00m generic_utils\u001b[39m.\u001b[39mSharedObjectSavingScope():\n\u001b[1;32m--> 153\u001b[0m     saved_model_save\u001b[39m.\u001b[39;49msave(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m    154\u001b[0m                           signatures, options, save_traces)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\save.py:93\u001b[0m, in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(\u001b[39m0\u001b[39m):\n\u001b[0;32m     92\u001b[0m   \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39mkeras_option_scope(save_traces):\n\u001b[1;32m---> 93\u001b[0m     saved_nodes, node_paths \u001b[39m=\u001b[39m save_lib\u001b[39m.\u001b[39;49msave_and_return_nodes(\n\u001b[0;32m     94\u001b[0m         model, filepath, signatures, options)\n\u001b[0;32m     96\u001b[0m   \u001b[39m# Save all metadata to a separate file in the SavedModel directory.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m   metadata \u001b[39m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1335\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   utils_impl\u001b[39m.\u001b[39mget_or_create_variables_dir(export_dir)\n\u001b[0;32m   1333\u001b[0m   ckpt_options \u001b[39m=\u001b[39m checkpoint_options\u001b[39m.\u001b[39mCheckpointOptions(\n\u001b[0;32m   1334\u001b[0m       experimental_io_device\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39mexperimental_io_device)\n\u001b[1;32m-> 1335\u001b[0m   object_saver\u001b[39m.\u001b[39;49msave(\n\u001b[0;32m   1336\u001b[0m       utils_impl\u001b[39m.\u001b[39;49mget_variables_path(export_dir), options\u001b[39m=\u001b[39;49mckpt_options)\n\u001b[0;32m   1337\u001b[0m builder_impl\u001b[39m.\u001b[39mcopy_assets_to_destination_dir(asset_info\u001b[39m.\u001b[39masset_filename_map,\n\u001b[0;32m   1338\u001b[0m                                             export_dir)\n\u001b[0;32m   1339\u001b[0m \u001b[39m# Note that this needs to be the last file operation when saving the\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m# SavedModel. Users rely on checking saved_model_dir/saved_model.pb as an\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m \u001b[39m# indication that the SavedModel is completely written.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1326\u001b[0m, in \u001b[0;36mTrackableSaver.save\u001b[1;34m(self, file_prefix, checkpoint_number, session, options, update_ckpt_state)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tensor_util\u001b[39m.\u001b[39mis_tensor(file_prefix):\n\u001b[0;32m   1324\u001b[0m   file_io\u001b[39m.\u001b[39mrecursive_create_dir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(file_prefix))\n\u001b[1;32m-> 1326\u001b[0m save_path, new_feed_additions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_cached_when_graph_building(\n\u001b[0;32m   1327\u001b[0m     file_prefix_tensor, object_graph_tensor, options, update_ckpt_state)\n\u001b[0;32m   1329\u001b[0m \u001b[39mif\u001b[39;00m new_feed_additions:\n\u001b[0;32m   1330\u001b[0m   feed_dict\u001b[39m.\u001b[39mupdate(new_feed_additions)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1271\u001b[0m, in \u001b[0;36mTrackableSaver._save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options, update_ckpt_state)\u001b[0m\n\u001b[0;32m   1268\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_save_operation, feed_additions\n\u001b[0;32m   1270\u001b[0m \u001b[39m# Execute the normal checkpoint, i.e., synchronous.\u001b[39;00m\n\u001b[1;32m-> 1271\u001b[0m \u001b[39mreturn\u001b[39;00m _run_save()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py:1217\u001b[0m, in \u001b[0;36mTrackableSaver._save_cached_when_graph_building.<locals>._run_save\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_save_object_graph \u001b[39m!=\u001b[39m graph_proto\n\u001b[0;32m   1210\u001b[0m     \u001b[39m# When executing eagerly, we need to re-create SaveableObjects each\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m     \u001b[39m# time save() is called so they pick up new Tensors passed to their\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[39m# constructors. That means the Saver needs to be copied with a new\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[39m# var_list.\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[39mor\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function()):\n\u001b[0;32m   1215\u001b[0m   saver \u001b[39m=\u001b[39m functional_saver\u001b[39m.\u001b[39mMultiDeviceSaver(named_saveable_objects,\n\u001b[0;32m   1216\u001b[0m                                             registered_savers)\n\u001b[1;32m-> 1217\u001b[0m   save_op \u001b[39m=\u001b[39m saver\u001b[39m.\u001b[39;49msave(file_prefix, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m   1218\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39m/cpu:0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   1219\u001b[0m     \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies([save_op]):\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py:375\u001b[0m, in \u001b[0;36mMultiDeviceSaver.save\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    373\u001b[0m   tf_function_save()\n\u001b[0;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m   \u001b[39mreturn\u001b[39;00m save_fn()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py:349\u001b[0m, in \u001b[0;36mMultiDeviceSaver.save.<locals>.save_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    344\u001b[0m   saved_prefixes\u001b[39m.\u001b[39mappend(shard_prefix)\n\u001b[0;32m    345\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(device):\n\u001b[0;32m    346\u001b[0m     \u001b[39m# _SingleDeviceSaver will use the CPU device when necessary, but\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[39m# initial read operations should be placed on the SaveableObject's\u001b[39;00m\n\u001b[0;32m    348\u001b[0m     \u001b[39m# device.\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     sharded_saves\u001b[39m.\u001b[39mappend(saver\u001b[39m.\u001b[39;49msave(shard_prefix, options))\n\u001b[0;32m    351\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies(sharded_saves):\n\u001b[0;32m    352\u001b[0m   \u001b[39m# Merge on the io_device if specified, otherwise co-locates the merge op\u001b[39;00m\n\u001b[0;32m    353\u001b[0m   \u001b[39m# with the last device used.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m   merge_device \u001b[39m=\u001b[39m (\n\u001b[0;32m    355\u001b[0m       options\u001b[39m.\u001b[39mexperimental_io_device \u001b[39mor\u001b[39;00m\n\u001b[0;32m    356\u001b[0m       saveable_object_util\u001b[39m.\u001b[39mset_cpu0(last_device))\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py:80\u001b[0m, in \u001b[0;36m_SingleDeviceSaver.save\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m     78\u001b[0m save_device \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mexperimental_io_device \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu:0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(save_device):\n\u001b[1;32m---> 80\u001b[0m   \u001b[39mreturn\u001b[39;00m io_ops\u001b[39m.\u001b[39;49msave_v2(file_prefix, tensor_names, tensor_slices, tensors)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1706\u001b[0m, in \u001b[0;36msave_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[0;32m   1704\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1706\u001b[0m   \u001b[39mreturn\u001b[39;00m save_v2_eager_fallback(\n\u001b[0;32m   1707\u001b[0m       prefix, tensor_names, shape_and_slices, tensors, name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1708\u001b[0m       ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m   1709\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m   1710\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1727\u001b[0m, in \u001b[0;36msave_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[0;32m   1725\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [prefix, tensor_names, shape_and_slices] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tensors)\n\u001b[0;32m   1726\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mdtypes\u001b[39m\u001b[39m\"\u001b[39m, _attr_dtypes)\n\u001b[1;32m-> 1727\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSaveV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat, attrs\u001b[39m=\u001b[39;49m_attrs,\n\u001b[0;32m   1728\u001b[0m                            ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1729\u001b[0m _result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1730\u001b[0m \u001b[39mreturn\u001b[39;00m _result\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save and restore models\n",
    "model_ffn.save(\"ffn_model\")\n",
    "model_ffn_nc.save(\"ffn_model_nc\")\n",
    "model_ffn_c.save(\"ffn_model_c\")\n",
    "model_ffn_n.save(\"ffn_model_n\")\n",
    "\n",
    "model_cnn.save(\"cnn_model\")\n",
    "model_cnn_nc.save(\"cnn_model_nc\")\n",
    "model_cnn_c.save(\"cnn_model_c\")\n",
    "model_cnn_n.save(\"cnn_model_n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # reload the model\n",
    "model_ffn_reload = tf.keras.models.load_model('ffn_model')\n",
    "model_ffn_nc_reload = tf.keras.models.load_model('ffn_model_nc')\n",
    "# model_cnn_reload = tf.keras.models.load_model('cnn_model')\n",
    "# saver = tf.train.Saver(max_to_keep=1)\n",
    "# with tf.Session() as sess:\n",
    "#     # train your model, then:\n",
    "#     savePath = saver.save(sess, 'my_ffn.ckpt')\n",
    "# # To restore:\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     saver = tf.train.import_meta_graph('my_ffn.ckpt.meta')\n",
    "#     saver.restore(sess, pathModel + 'someDir/my_model.ckpt')\n",
    "#     # access a variable from the saved Graph, and so on:\n",
    "#     someVar = sess.run('varName:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 14s 436ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model_ffn_reload.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Reset \n",
    "# val_data_gen.reset()\n",
    "\n",
    "# # Evaluate on Validation data\n",
    "# scores = model.evaluate(val_data_gen)\n",
    "# print(\"%s%s: %.2f%%\" % (\"evaluate \",model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out functionality to\n",
    "n_sim = 2\n",
    "test_accs = [np.nan]*n_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 21s 623ms/step - loss: 4.1408 - accuracy: 0.0231\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 4.5930 - accuracy: 0.0173\n",
      "[0.023121386766433716, 0.017341040074825287]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# _, train_acc = model_ffn.evaluate(train_generator, verbose=0)\n",
    "_, test_accs[j] = model_ffn_reload.evaluate(test_generator)\n",
    "_, test_accs[1] = model_ffn_nc_reload.evaluate(test_generator)\n",
    "print(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_digits = np.argmax(results,axis=1)\n",
    "test_labels = test_generator.classes\n",
    "len(test_labels)\n",
    "len(pred_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine model fits and accuracy assessments into one function\n",
    "def network_sim(train_generator,test_generator,n_epochs,noise_sd=0,contrast_factor=0):\n",
    "    \"\"\"Fit Feed Forward and Convolutional Neural Networks with 2 factors: Random Noise and Random Contrast\n",
    "    parameters:\n",
    "        train_generator\n",
    "        test_generator\n",
    "        noise_sd: float [0.0,1.0], default = 0\n",
    "            sd of Gaussian(0,sd) random noise to be added during training\n",
    "        contrast_factor: float [0.0,1.0], defauly = 0\n",
    "            factor to scale random contrast adjustment of images; \n",
    "            factor applied using following formula: \n",
    "            layer computes the mean of the image pixels in the channel and then adjusts each component x\n",
    "            of each pixel to (x - mean) * contrast_factor + mean\n",
    "    returns: *dictionary* {FFN_accuracy,CNN_accuracy}\n",
    "    \"\"\"\n",
    "    # get number of classes in training data\n",
    "    num_classes = len(np.unique(train_generator.classes))\n",
    "    # define early stopping criteria\n",
    "    es = EarlyStopping(monitor='loss',patience=3,mode='min')\n",
    "\n",
    "    # feed forward nn fit\n",
    "    model_ffn_nc = Sequential([\n",
    "        RandomContrast(factor=contrast_factor, input_shape=(150, 150, 3)),\n",
    "        GaussianNoise(noise_sd),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        # 5 classes: so get 5 output nuerons with softmax activiation function (to give probability of each class)\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    # there may also be some overfitting, so using some dropout could be helpful\n",
    "\n",
    "    model_ffn_nc.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    print(f'Fitting feed forward network with Gaussian(0,{noise_sd}) noise and {contrast_factor} random contrast')\n",
    "    model_ffn_nc.fit(train_generator, epochs=n_epochs,\n",
    "                #   steps_per_epoch=10,\n",
    "                    callbacks=[es])\n",
    "    \n",
    "\n",
    "    # cnn fit\n",
    "    model_cnn_nc = Sequential([\n",
    "        # syntax: Conv2D(num_filters, kernel_size (shape1,shape2), activation, input_shape for first layer)\n",
    "        # recall: adding dropout can be helpful to remedy overfitting\n",
    "        RandomContrast(factor=contrast_factor, input_shape=(150, 150, 3)),\n",
    "        GaussianNoise(noise_sd),\n",
    "        Conv2D(32, (3, 3), activation='relu'), #input_shape=(150, 150, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # Dropout(0.1),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # Dropout(0.1),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # Dropout(0.1),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # Dropout(0.1),\n",
    "        # after convolutional layers, flatten the output, then use 1-2(/3?) dense layers\n",
    "        Flatten(),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        Dense(256, activation='tanh'),\n",
    "        Dropout(0.2),\n",
    "        # GaussianNoise(noise_sd),\n",
    "        # Dense(128, activation='relu'),\n",
    "        # Dropout(0.1),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model_cnn_nc.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    print(f'Fitting CNN with Gaussian(0,{noise_sd}) noise and {contrast_factor} random contrast')\n",
    "    model_cnn_nc.fit(train_generator, epochs=n_epochs,\n",
    "                    callbacks = [es])\n",
    "    # default is to take len(train_generator steps per epoch)\n",
    "\n",
    "    # accuracy evaluations\n",
    "    _, test_acc_ffn = model_ffn_nc.evaluate(test_generator)\n",
    "    _, test_acc_cnn = model_cnn_nc.evaluate(test_generator)\n",
    "\n",
    "    return {\"FFN_accuracy\": test_acc_ffn, \"CNN_accuracy\": test_acc_cnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting feed forward network with Gaussian(0,0) and 0 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 51s 369ms/step - loss: 4.0248 - accuracy: 0.0397\n",
      "Fitting CNN with Gaussian(0,0) and 0 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 81s 583ms/step - loss: 3.7930 - accuracy: 0.0584\n",
      "33/33 [==============================] - 13s 382ms/step - loss: 3.8267 - accuracy: 0.0539\n",
      "33/33 [==============================] - 13s 372ms/step - loss: 3.6911 - accuracy: 0.1050\n",
      "Fitting feed forward network with Gaussian(0,0.2) and 0.1 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 52s 363ms/step - loss: 4.0177 - accuracy: 0.0378\n",
      "Fitting CNN with Gaussian(0,0.2) and 0.1 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 85s 609ms/step - loss: 3.7881 - accuracy: 0.0562\n",
      "33/33 [==============================] - 10s 308ms/step - loss: 3.8277 - accuracy: 0.0520\n",
      "33/33 [==============================] - 12s 353ms/step - loss: 3.7675 - accuracy: 0.0684\n",
      "Fitting feed forward network with Gaussian(0,0.2) and 0 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 45s 321ms/step - loss: 3.9837 - accuracy: 0.0352\n",
      "Fitting CNN with Gaussian(0,0.2) and 0 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 73s 531ms/step - loss: 3.8036 - accuracy: 0.0536\n",
      "33/33 [==============================] - 10s 297ms/step - loss: 3.8275 - accuracy: 0.0530\n",
      "33/33 [==============================] - 12s 350ms/step - loss: 3.7489 - accuracy: 0.0694\n",
      "Fitting feed forward network with Gaussian(0,0) and 0.1 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 47s 339ms/step - loss: 4.0555 - accuracy: 0.0359\n",
      "Fitting CNN with Gaussian(0,0) and 0.1 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "133/133 [==============================] - 79s 575ms/step - loss: 3.7831 - accuracy: 0.0572\n",
      "33/33 [==============================] - 10s 311ms/step - loss: 3.8274 - accuracy: 0.0520\n",
      "33/33 [==============================] - 12s 366ms/step - loss: 3.6852 - accuracy: 0.0915\n"
     ]
    }
   ],
   "source": [
    "# test network_sim\n",
    "baseline_results = network_sim(train_generator,test_generator,n_epochs=1)\n",
    "nc_results = network_sim(train_generator,test_generator,n_epochs=1,noise_sd=0.2,contrast_factor=0.1)\n",
    "n_results = network_sim(train_generator,test_generator,n_epochs=1,noise_sd=0.2,contrast_factor=0)\n",
    "c_results = network_sim(train_generator,test_generator,n_epochs=1,noise_sd=0,contrast_factor=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test list structure before aplying in loop\n",
    "n_sim = 3\n",
    "ffn_base_accs = [np.nan]*n_sim\n",
    "ffn_nc_accs = [np.nan]*n_sim\n",
    "ffn_n_accs = [np.nan]*n_sim\n",
    "ffn_c_accs = [np.nan]*n_sim\n",
    "cnn_base_accs = [np.nan]*n_sim\n",
    "cnn_nc_accs = [np.nan]*n_sim\n",
    "cnn_n_accs = [np.nan]*n_sim\n",
    "cnn_c_accs = [np.nan]*n_sim\n",
    "\n",
    "ffn_base_accs[0] = baseline_results[\"FFN_accuracy\"]\n",
    "ffn_nc_accs[0] = nc_results[\"FFN_accuracy\"]\n",
    "ffn_n_accs[0] = n_results[\"FFN_accuracy\"]\n",
    "ffn_c_accs[0] = c_results[\"FFN_accuracy\"]\n",
    "\n",
    "cnn_base_accs[0] = baseline_results[\"CNN_accuracy\"]\n",
    "cnn_nc_accs[0] = nc_results[\"CNN_accuracy\"]\n",
    "cnn_n_accs[0] = n_results[\"CNN_accuracy\"]\n",
    "cnn_c_accs[0] = c_results[\"CNN_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "Fitting feed forward network with Gaussian(0,0) noise and 0 random contrast\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      " 20/133 [===>..........................] - ETA: 35s - loss: 4.8548 - accuracy: 0.0211"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tyler\\Dropbox\\BYU\\STAT 666\\Term Project\\work.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrun \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# train networks\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m baseline_results \u001b[39m=\u001b[39m network_sim(train_generator,test_generator,n_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m nc_results \u001b[39m=\u001b[39m network_sim(train_generator,test_generator,n_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,noise_sd\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,contrast_factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m n_results \u001b[39m=\u001b[39m network_sim(train_generator,test_generator,n_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,noise_sd\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,contrast_factor\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\tyler\\Dropbox\\BYU\\STAT 666\\Term Project\\work.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model_ffn_nc\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFitting feed forward network with Gaussian(0,\u001b[39m\u001b[39m{\u001b[39;00mnoise_sd\u001b[39m}\u001b[39;00m\u001b[39m) noise and \u001b[39m\u001b[39m{\u001b[39;00mcontrast_factor\u001b[39m}\u001b[39;00m\u001b[39m random contrast\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m model_ffn_nc\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49mn_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m             \u001b[39m#   steps_per_epoch=10,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[es])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# cnn fit\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m model_cnn_nc \u001b[39m=\u001b[39m Sequential([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m# syntax: Conv2D(num_filters, kernel_size (shape1,shape2), activation, input_shape for first layer)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     RandomContrast(contrast_factor, input_shape\u001b[39m=\u001b[39m(\u001b[39m150\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m3\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     Dense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/Dropbox/BYU/STAT%20666/Term%20Project/work.ipynb#X51sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# repeat process for simulation study\n",
    "# then can also decide if we want to up noise/contrast or change filter\n",
    "\n",
    "n_sims = 20\n",
    "# initialize result lists\n",
    "ffn_base_accs = [np.nan]*n_sim\n",
    "ffn_nc_accs = [np.nan]*n_sim\n",
    "ffn_n_accs = [np.nan]*n_sim\n",
    "ffn_c_accs = [np.nan]*n_sim\n",
    "cnn_base_accs = [np.nan]*n_sim\n",
    "cnn_nc_accs = [np.nan]*n_sim\n",
    "cnn_n_accs = [np.nan]*n_sim\n",
    "cnn_c_accs = [np.nan]*n_sim\n",
    "for j in range(n_sims):\n",
    "    print(f\"run {j+1}\")\n",
    "    # train networks\n",
    "    baseline_results = network_sim(train_generator,test_generator,n_epochs=1)\n",
    "    nc_results = network_sim(train_generator,test_generator,n_epochs=1,noise_sd=0.2,contrast_factor=0.1)\n",
    "    n_results = network_sim(train_generator,test_generator,n_epochs=1,noise_sd=0.2,contrast_factor=0)\n",
    "    c_results = network_sim(train_generator,test_generator,n_epochs=1,noise_sd=0,contrast_factor=0.1)\n",
    "\n",
    "    # export results\n",
    "    ffn_base_accs[j] = baseline_results[\"FFN_accuracy\"]\n",
    "    ffn_nc_accs[j] = nc_results[\"FFN_accuracy\"]\n",
    "    ffn_n_accs[j] = n_results[\"FFN_accuracy\"]\n",
    "    ffn_c_accs[j] = c_results[\"FFN_accuracy\"]\n",
    "\n",
    "    cnn_base_accs[j] = baseline_results[\"CNN_accuracy\"]\n",
    "    cnn_nc_accs[j] = nc_results[\"CNN_accuracy\"]\n",
    "    cnn_n_accs[j] = n_results[\"CNN_accuracy\"]\n",
    "    cnn_c_accs[j] = c_results[\"CNN_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as pickles \n",
    "# ('wb': 'write byte/binary' => write using byte data: in binary mode)\n",
    "# ffn\n",
    "fileObj = open('ffn_base_accs.obj', 'wb')\n",
    "pickle.dump(ffn_base_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('ffn_nc_accs.obj', 'wb')\n",
    "pickle.dump(ffn_nc_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('ffn_n_accs.obj', 'wb')\n",
    "pickle.dump(ffn_n_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('ffn_c_accs.obj', 'wb')\n",
    "pickle.dump(ffn_c_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "# cnn\n",
    "fileObj = open('cnn_base_accs.obj', 'wb')\n",
    "pickle.dump(ffn_base_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('cnn_nc_accs.obj', 'wb')\n",
    "pickle.dump(ffn_nc_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('cnn_n_accs.obj', 'wb')\n",
    "pickle.dump(ffn_n_accs, fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('cnn_c_accs.obj', 'wb')\n",
    "pickle.dump(ffn_c_accs, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.053949903696775436, 0.10019268095493317, 0.060693640261888504, 0.08670520037412643, 0.09248554706573486, 0.08959537744522095, 0.059730250388383865, 0.05202312022447586, 0.06262042373418808, 0.05202312022447586, 0.09152215719223022, 0.05876686051487923, 0.05684007704257965, 0.05202312022447586, 0.08863198757171631, 0.05202312022447586, 0.05202312022447586, 0.09730250388383865, 0.08863198757171631, 0.08863198757171631]\n",
      "[0.2707129120826721, 0.2678227424621582, 0.2572254240512848, 0.26396918296813965, 0.26396918296813965, 0.2543352544307709, 0.2524084746837616, 0.26204240322113037, 0.24855491518974304, 0.2543352544307709, 0.25626203417778015, 0.25626203417778015, 0.24662813544273376, 0.2447013556957245, 0.25818881392478943, 0.2524084746837616, 0.2475915253162384, 0.24951830506324768, 0.24181117117404938, 0.2774566411972046]\n",
      "ANN BASE accuracy: 0.07182080931961536 with sd: 0.018280268214057833\n",
      "CNN BASE accuracy: 0.256310211867094 with sd: 0.008946969233539902\n",
      "ANN NOISY accuracy: 0.06950866989791393 with sd: 0.01692465920256929\n",
      "CNN NOISY accuracy: 0.23338150084018708 with sd: 0.009409108101078232\n",
      "ANN GRAY accuracy: 0.06912331320345402 with sd: 0.018179461034360397\n",
      "CNN GRAY accuracy: 0.1932562619447708 with sd: 0.0073394982141140866\n",
      "ANN NOISY GRAY accuracy: 0.06035645473748445 with sd: 0.012781826745628501\n",
      "CNN NOISY GRAY accuracy: 0.17817919105291366 with sd: 0.007036548988244047\n"
     ]
    }
   ],
   "source": [
    "# deserialize (reload) objects\n",
    "fileObj = open('./shortsim2/fn_base_accs.obj', 'rb')\n",
    "ffn_base_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "print(ffn_base_accs_reload2)\n",
    "\n",
    "fileObj = open('./shortsim2/ffn_c_accs.obj', 'rb')\n",
    "ffn_c_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./shortsim2/fn_n_accs.obj', 'rb')\n",
    "ffn_n_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./shortsim2/ffn_nc_accs.obj', 'rb')\n",
    "ffn_nc_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./shortsim2/cnn_base_accs.obj', 'rb')\n",
    "cnn_base_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "print(cnn_base_accs_reload2)\n",
    "\n",
    "fileObj = open('./shortsim2/cnn_c_accs.obj', 'rb')\n",
    "cnn_c_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./shortsim2/cnn_n_accs.obj', 'rb')\n",
    "cnn_n_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./shortsim2/cnn_nc_accs.obj', 'rb')\n",
    "cnn_nc_accs_reload2 = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "\n",
    "print(\"ANN BASE accuracy:\", np.mean(ffn_base_accs_reload2), \"with sd:\", np.std(ffn_base_accs_reload2))\n",
    "print(\"CNN BASE accuracy:\", np.mean(cnn_base_accs_reload2), \"with sd:\", np.std(cnn_base_accs_reload2))\n",
    "print(\"ANN NOISY accuracy:\", np.mean(ffn_n_accs_reload2), \"with sd:\", np.std(ffn_n_accs_reload2))\n",
    "print(\"CNN NOISY accuracy:\", np.mean(cnn_n_accs_reload2), \"with sd:\", np.std(cnn_n_accs_reload2))\n",
    "print(\"ANN GRAY accuracy:\", np.mean(ffn_c_accs_reload2), \"with sd:\", np.std(ffn_c_accs_reload2))\n",
    "print(\"CNN GRAY accuracy:\", np.mean(cnn_c_accs_reload2), \"with sd:\", np.std(cnn_c_accs_reload2))\n",
    "print(\"ANN NOISY GRAY accuracy:\", np.mean(ffn_nc_accs_reload2), \"with sd:\", np.std(ffn_nc_accs_reload2))\n",
    "print(\"CNN NOISY GRAY accuracy:\", np.mean(cnn_nc_accs_reload2), \"with sd:\", np.std(cnn_nc_accs_reload2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05202312022447586, 0.05202312022447586, 0.05202312022447586, 0.09730250388383865, 0.05587668716907501, 0.05202312022447586, 0.05202312022447586, 0.05202312022447586, 0.06551060080528259, 0.08863198757171631, 0.06262042373418808, 0.05202312022447586, 0.09152215719223022, 0.054913293570280075, 0.1011560708284378, 0.05202312022447586, 0.0529865138232708, 0.06262042373418808, 0.08863198757171631, 0.08863198757171631]\n",
      "[0.2504816949367523, 0.24662813544273376, 0.2697495222091675, 0.2350674420595169, 0.25626203417778015, 0.25144508481025696, 0.2447013556957245, 0.23892100155353546, 0.2658959627151489, 0.25626203417778015, 0.24181117117404938, 0.26204240322113037, 0.26107898354530334, 0.26107898354530334, 0.26685935258865356, 0.2572254240512848, 0.24566474556922913, 0.24662813544273376, 0.24662813544273376, 0.24277456104755402]\n",
      "ANN BASE accuracy: 0.06632947996258735 with sd: 0.01786376400760015\n",
      "CNN BASE accuracy: 0.2523603081703186 with sd: 0.009708167213140328\n",
      "ANN NOISY accuracy: 0.07230250500142574 with sd: 0.0179109807356446\n",
      "CNN NOISY accuracy: 0.22148362174630165 with sd: 0.010539782460706125\n",
      "ANN GRAY accuracy: 0.06156069319695234 with sd: 0.013411221518242712\n",
      "CNN GRAY accuracy: 0.193256264179945 with sd: 0.009387009653814898\n",
      "ANN NOISY GRAY accuracy: 0.05910404622554779 with sd: 0.013122204956629182\n",
      "CNN NOISY GRAY accuracy: 0.17504816949367524 with sd: 0.006548934591988608\n"
     ]
    }
   ],
   "source": [
    "# deserialize (reload) objects\n",
    "# original sim: 12 epochs, 20 sims, to gray scale as in to 2d, rather than b&w\n",
    "fileObj = open('./pickles_shortsim/ffn_base_accs.obj', 'rb')\n",
    "ffn_base_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "print(ffn_base_accs_reload)\n",
    "\n",
    "fileObj = open('./pickles_shortsim/ffn_c_accs.obj', 'rb')\n",
    "ffn_c_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./pickles_shortsim/ffn_n_accs.obj', 'rb')\n",
    "ffn_n_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./pickles_shortsim/ffn_nc_accs.obj', 'rb')\n",
    "ffn_nc_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./pickles_shortsim/cnn_base_accs.obj', 'rb')\n",
    "cnn_base_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "print(cnn_base_accs_reload)\n",
    "\n",
    "fileObj = open('./pickles_shortsim/cnn_c_accs.obj', 'rb')\n",
    "cnn_c_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./pickles_shortsim/cnn_n_accs.obj', 'rb')\n",
    "cnn_n_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./pickles_shortsim/cnn_nc_accs.obj', 'rb')\n",
    "cnn_nc_accs_reload = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "\n",
    "print(\"ANN BASE accuracy:\", np.mean(ffn_base_accs_reload), \"with sd:\", np.std(ffn_base_accs_reload))\n",
    "print(\"CNN BASE accuracy:\", np.mean(cnn_base_accs_reload), \"with sd:\", np.std(cnn_base_accs_reload))\n",
    "print(\"ANN NOISY accuracy:\", np.mean(ffn_n_accs_reload), \"with sd:\", np.std(ffn_n_accs_reload))\n",
    "print(\"CNN NOISY accuracy:\", np.mean(cnn_n_accs_reload), \"with sd:\", np.std(cnn_n_accs_reload))\n",
    "print(\"ANN GRAY accuracy:\", np.mean(ffn_c_accs_reload), \"with sd:\", np.std(ffn_c_accs_reload))\n",
    "print(\"CNN GRAY accuracy:\", np.mean(cnn_c_accs_reload), \"with sd:\", np.std(cnn_c_accs_reload))\n",
    "print(\"ANN NOISY GRAY accuracy:\", np.mean(ffn_nc_accs_reload), \"with sd:\", np.std(ffn_nc_accs_reload))\n",
    "print(\"CNN NOISY GRAY accuracy:\", np.mean(cnn_nc_accs_reload), \"with sd:\", np.std(cnn_nc_accs_reload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>SD Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN_BASE</td>\n",
       "      <td>0.066329</td>\n",
       "      <td>0.017864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANN_NOISY</td>\n",
       "      <td>0.072303</td>\n",
       "      <td>0.017911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANN_GRAY</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.013411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANN_NOISY_GRAY</td>\n",
       "      <td>0.059104</td>\n",
       "      <td>0.013122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN_BASE</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>0.009708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN_NOISY</td>\n",
       "      <td>0.221484</td>\n",
       "      <td>0.010540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN_GRAY</td>\n",
       "      <td>0.193256</td>\n",
       "      <td>0.009387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN_NOISY_GRAY</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>0.006549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Method  Mean Accuracy  SD Accuracy\n",
       "0        ANN_BASE       0.066329     0.017864\n",
       "1       ANN_NOISY       0.072303     0.017911\n",
       "2        ANN_GRAY       0.061561     0.013411\n",
       "3  ANN_NOISY_GRAY       0.059104     0.013122\n",
       "4        CNN_BASE       0.252360     0.009708\n",
       "5       CNN_NOISY       0.221484     0.010540\n",
       "6        CNN_GRAY       0.193256     0.009387\n",
       "7  CNN_NOISY_GRAY       0.175048     0.006549"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_results_dict = {\"Method\": [\"ANN_BASE\",\"ANN_NOISY\",\"ANN_GRAY\", \"ANN_NOISY_GRAY\",\"CNN_BASE\",\"CNN_NOISY\",\"CNN_GRAY\", \"CNN_NOISY_GRAY\"],\n",
    "                    \"Mean Accuracy\":[np.mean(ffn_base_accs_reload),np.mean(ffn_n_accs_reload),np.mean(ffn_c_accs_reload),np.mean(ffn_nc_accs_reload),\n",
    "                                     np.mean(cnn_base_accs_reload),np.mean(cnn_n_accs_reload),np.mean(cnn_c_accs_reload),np.mean(cnn_nc_accs_reload)],\n",
    "                    \"SD Accuracy\": [np.std(ffn_base_accs_reload),np.std(ffn_n_accs_reload),np.std(ffn_c_accs_reload),np.std(ffn_nc_accs_reload),\n",
    "                                    np.std(cnn_base_accs_reload),np.std(cnn_n_accs_reload),np.std(cnn_c_accs_reload),np.std(cnn_nc_accs_reload)]}\n",
    "sim_res_df = pd.DataFrame(sim_results_dict)\n",
    "sim_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.to_latex of            Method  Mean Accuracy  SD Accuracy\n",
       "0        ANN_BASE       0.066329     0.017864\n",
       "1       ANN_NOISY       0.072303     0.017911\n",
       "2        ANN_GRAY       0.061561     0.013411\n",
       "3  ANN_NOISY_GRAY       0.059104     0.013122\n",
       "4        CNN_BASE       0.252360     0.009708\n",
       "5       CNN_NOISY       0.221484     0.010540\n",
       "6        CNN_GRAY       0.193256     0.009387\n",
       "7  CNN_NOISY_GRAY       0.175048     0.006549>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output table to latex\n",
    "sim_res_df.to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08863198757171631, 0.05684007704257965, 0.06551060080528259, 0.05876686051487923, 0.05684007704257965, 0.05876686051487923, 0.06358381360769272, 0.08766859024763107, 0.05202312022447586, 0.05202312022447586, 0.06647399067878723, 0.060693640261888504, 0.08766859024763107, 0.05202312022447586, 0.05202312022447586, 0.08381503075361252, 0.08863198757171631, 0.09826589375734329, 0.08477842062711716, 0.05202312022447586]\n",
      "[0.2543352544307709, 0.2572254240512848, 0.2350674420595169, 0.25337186455726624, 0.2572254240512848, 0.26204240322113037, 0.25626203417778015, 0.23795761168003082, 0.24277456104755402, 0.23795761168003082, 0.2552986443042755, 0.2524084746837616, 0.2572254240512848, 0.2273603081703186, 0.25337186455726624, 0.23892100155353546, 0.25144508481025696, 0.25818881392478943, 0.2524084746837616, 0.25626203417778015]\n",
      "ANN BASE accuracy: 0.06835260111838579 with sd: 0.01556845755402284\n",
      "CNN BASE accuracy: 0.249855487793684 with sd: 0.009301962132233057\n",
      "ANN NOISY accuracy: 0.06517341025173665 with sd: 0.01531542069351956\n",
      "CNN NOISY accuracy: 0.21690751388669013 with sd: 0.011855093604871733\n",
      "ANN GRAY accuracy: 0.06290944088250398 with sd: 0.015348184299078577\n",
      "CNN GRAY accuracy: 0.19108863025903702 with sd: 0.00958695226414833\n",
      "ANN NOISY GRAY accuracy: 0.05703275501728058 with sd: 0.00908657162025083\n",
      "CNN NOISY GRAY accuracy: 0.1771676279604435 with sd: 0.008236288820789904\n"
     ]
    }
   ],
   "source": [
    "# deserialize (reload) objects\n",
    "# corrected sim: 12 epochs, 20 sims, fully to gray scale, back as 3d rgb image\n",
    "fileObj = open('./sim_gray_corrected/ffn_base_accs.obj', 'rb')\n",
    "ffn_base_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "print(ffn_base_accs_reloadc)\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/ffn_c_accs.obj', 'rb')\n",
    "ffn_c_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/ffn_n_accs.obj', 'rb')\n",
    "ffn_n_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/ffn_nc_accs.obj', 'rb')\n",
    "ffn_nc_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/cnn_base_accs.obj', 'rb')\n",
    "cnn_base_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "print(cnn_base_accs_reloadc)\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/cnn_c_accs.obj', 'rb')\n",
    "cnn_c_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/cnn_n_accs.obj', 'rb')\n",
    "cnn_n_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('./sim_gray_corrected/cnn_nc_accs.obj', 'rb')\n",
    "cnn_nc_accs_reloadc = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "\n",
    "print(\"ANN BASE accuracy:\", np.mean(ffn_base_accs_reloadc), \"with sd:\", np.std(ffn_base_accs_reloadc))\n",
    "print(\"CNN BASE accuracy:\", np.mean(cnn_base_accs_reloadc), \"with sd:\", np.std(cnn_base_accs_reloadc))\n",
    "print(\"ANN NOISY accuracy:\", np.mean(ffn_n_accs_reloadc), \"with sd:\", np.std(ffn_n_accs_reloadc))\n",
    "print(\"CNN NOISY accuracy:\", np.mean(cnn_n_accs_reloadc), \"with sd:\", np.std(cnn_n_accs_reloadc))\n",
    "print(\"ANN GRAY accuracy:\", np.mean(ffn_c_accs_reloadc), \"with sd:\", np.std(ffn_c_accs_reloadc))\n",
    "print(\"CNN GRAY accuracy:\", np.mean(cnn_c_accs_reloadc), \"with sd:\", np.std(cnn_c_accs_reloadc))\n",
    "print(\"ANN NOISY GRAY accuracy:\", np.mean(ffn_nc_accs_reloadc), \"with sd:\", np.std(ffn_nc_accs_reloadc))\n",
    "print(\"CNN NOISY GRAY accuracy:\", np.mean(cnn_nc_accs_reloadc), \"with sd:\", np.std(cnn_nc_accs_reloadc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\begin{tabular}{llrr}\n",
      " & Method & Mean Accuracy & SD \\\\\n",
      "0 & DNN BASE & 0.068353 & 0.015568 \\\\\n",
      "1 & DNN NOISY & 0.065173 & 0.015315 \\\\\n",
      "2 & DNN GRAY & 0.062909 & 0.015348 \\\\\n",
      "3 & DNN NOISY+GRAY & 0.057033 & 0.009087 \\\\\n",
      "4 & CNN BASE & 0.249855 & 0.009302 \\\\\n",
      "5 & CNN NOISY & 0.216908 & 0.011855 \\\\\n",
      "6 & CNN GRAY & 0.191089 & 0.009587 \\\\\n",
      "7 & CNN NOISY+GRAY & 0.177168 & 0.008236 \\\\\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_results_dict = {\"Method\": [\"DNN BASE\",\"DNN NOISY\",\"DNN GRAY\", \"DNN NOISY+GRAY\",\"CNN BASE\",\"CNN NOISY\",\"CNN GRAY\", \"CNN NOISY+GRAY\"],\n",
    "                    \"Mean Accuracy\":[np.mean(ffn_base_accs_reloadc),np.mean(ffn_n_accs_reloadc),np.mean(ffn_c_accs_reloadc),np.mean(ffn_nc_accs_reloadc),\n",
    "                                     np.mean(cnn_base_accs_reloadc),np.mean(cnn_n_accs_reloadc),np.mean(cnn_c_accs_reloadc),np.mean(cnn_nc_accs_reloadc)],\n",
    "                    \"SD\": [np.std(ffn_base_accs_reloadc),np.std(ffn_n_accs_reloadc),np.std(ffn_c_accs_reloadc),np.std(ffn_nc_accs_reloadc),\n",
    "                                    np.std(cnn_base_accs_reloadc),np.std(cnn_n_accs_reloadc),np.std(cnn_c_accs_reloadc),np.std(cnn_nc_accs_reloadc)]}\n",
    "sim_res_dfc = pd.DataFrame(sim_results_dict)\n",
    "sim_res_dfc\n",
    "\n",
    "# output table to latex\n",
    "print(sim_res_dfc.style.to_latex(position = 't'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00        24\n",
      "           6       0.00      0.00      0.00        17\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       0.00      0.00      0.00        21\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.08      0.04      0.05        26\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.00      0.00      0.00        16\n",
      "          13       0.00      0.00      0.00        23\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.00      0.00      0.00        22\n",
      "          16       0.00      0.00      0.00        18\n",
      "          17       0.00      0.00      0.00        22\n",
      "          18       0.00      0.00      0.00        42\n",
      "          19       0.00      0.00      0.00        22\n",
      "          20       0.05      0.98      0.10        54\n",
      "          21       0.00      0.00      0.00        17\n",
      "          22       0.00      0.00      0.00        16\n",
      "          23       0.00      0.00      0.00        23\n",
      "          24       0.00      0.00      0.00        21\n",
      "          25       0.00      0.00      0.00        18\n",
      "          26       0.00      0.00      0.00        38\n",
      "          27       0.00      0.00      0.00        23\n",
      "          28       0.00      0.00      0.00        22\n",
      "          29       0.00      0.00      0.00        21\n",
      "          30       0.00      0.00      0.00        24\n",
      "          31       0.00      0.00      0.00        29\n",
      "          32       0.00      0.00      0.00        41\n",
      "          33       0.00      0.00      0.00        20\n",
      "          34       0.00      0.00      0.00        18\n",
      "          35       0.00      0.00      0.00        28\n",
      "          36       0.00      0.00      0.00        16\n",
      "          37       0.00      0.00      0.00        23\n",
      "          38       0.00      0.00      0.00        22\n",
      "          39       0.00      0.00      0.00        21\n",
      "          40       0.00      0.00      0.00        16\n",
      "          41       0.00      0.00      0.00        17\n",
      "          42       0.00      0.00      0.00        19\n",
      "          43       0.00      0.00      0.00        19\n",
      "          44       0.00      0.00      0.00        19\n",
      "          45       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.05      1038\n",
      "   macro avg       0.00      0.02      0.00      1038\n",
      "weighted avg       0.00      0.05      0.01      1038\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tyler\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tyler\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tyler\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# attempt to look at confusion matrix/classification report\n",
    "# predictions appear to be in shuffled order,\n",
    "# so performance not matching what is shown when model.evaluate() is run\n",
    "\n",
    "# test_labels = test_generator.classes_\n",
    "# pred_digits = np.argmax(model_cnn.predict(test_generator),axis=1)\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# confusion_matrix(y_true=test_labels,y_pred=pred_digits)\n",
    "# print(classification_report(test_labels,pred_digits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
